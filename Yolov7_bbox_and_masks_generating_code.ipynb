{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Citations:\n",
        "# 1) Landup, David. “Instance Segmentation with Yolov7 in Python.” Stack Abuse, Stack Abuse, 12 Oct. 2022, https://stackabuse.com/instance-segmentation-with-yolov7-in-python/. \n",
        "\n",
        "# 2) Kin-Yiu, W. (2022). yolov7 [Repository]. GitHub. https://github.com/WongKinYiu/yolov7\n",
        "#    Wang, Chien-Yao, Alexey Bochkovskiy, and Hong-Yuan Mark Liao. \"YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors.\" arXiv preprint arXiv:2207.02696 (2022).\n"
      ],
      "metadata": {
        "id": "1-d57D2YHppi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# Set the directory in which the masks will be stored\n",
        "##########################################################"
      ],
      "metadata": {
        "id": "Qnr_IzmDFuhn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ2R8zgxT8um",
        "outputId": "7fe114a5-4585-476c-db4f-46ea8a8e09e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images_dir = '/content/gdrive/MyDrive/Dataset/Scenario 5/masks'"
      ],
      "metadata": {
        "id": "f3sMNSJXT9gW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# Clone the relevant repository, install and import the required libraries\n",
        "##########################################################"
      ],
      "metadata": {
        "id": "rS47zQMDJEQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0qFlQzht7Cj"
      },
      "outputs": [],
      "source": [
        "! git clone -b mask https://github.com/WongKinYiu/yolov7.git\n",
        "! pip install pyyaml==5.1\n",
        "! pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "ij3uLvRWuLV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov7\n",
        "! curl -L https://github.com/WongKinYiu/yolov7/releases/download/v0.1/yolov7-mask.pt -o yolov7-mask.pt"
      ],
      "metadata": {
        "id": "KmNKawDbuPji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available.\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n"
      ],
      "metadata": {
        "id": "YCMoLWzXvgks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cd3eee-8e16-436a-fdac-b4cbf95874fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import cv2\n",
        "import yaml\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "\n",
        "from utils.datasets import letterbox\n",
        "from utils.general import non_max_suppression_mask_conf\n",
        "\n",
        "from detectron2.modeling.poolers import ROIPooler\n",
        "from detectron2.structures import Boxes\n",
        "from detectron2.utils.memory import retry_if_cuda_oom\n",
        "from detectron2.layers import paste_masks_in_image"
      ],
      "metadata": {
        "id": "oqGyy6fyuTlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device_count = torch.cuda.device_count()\n",
        "    for i in range(device_count):\n",
        "        print(f\"Device {i}: {torch.cuda.get_device_name(i)}\")\n",
        "else:\n",
        "    print(\"CUDA is not available.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxR6m0-wwGvm",
        "outputId": "7d5d3eeb-011a-4624-b979-262c93d309fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device 0: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "\n",
        "print(torch.cuda.current_device())\n",
        "\n",
        "\n",
        "print(torch.cuda.device(0))\n",
        "\n",
        "\n",
        "print(torch.cuda.device_count())\n",
        "\n",
        "\n",
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "id": "m-cWmxjswgEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1c3bed9-0480-4cdf-bde5-4837626c45e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "0\n",
            "<torch.cuda.device object at 0x7f70fd0f1760>\n",
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################################\n",
        "# Helper functions\n",
        "##########################################################"
      ],
      "metadata": {
        "id": "yw6jJI7zK1Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with open('data/hyp.scratch.mask.yaml') as f:\n",
        "    hyp = yaml.load(f, Loader=yaml.FullLoader)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def load_model():\n",
        "    model = torch.load('yolov7-mask.pt', map_location=device)['model']\n",
        "    # Put in inference mode\n",
        "    model.eval()\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        # half() turns predictions into float16 tensors\n",
        "        # which significantly lowers inference time\n",
        "        model.half().to(device)\n",
        "    return model\n",
        "\n",
        "model = load_model()"
      ],
      "metadata": {
        "id": "WyACRITPuuyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_inference(url):\n",
        "    image = cv2.imread(url) # shape: (480, 640, 3)\n",
        "    # print('image.shape',image.shape)\n",
        "    # Resize and pad image\n",
        "    image = letterbox(image, 960, stride=64, auto=True)[0] # shape: (480, 640, 3)\n",
        "    # Apply transforms\n",
        "    image = transforms.ToTensor()(image) # torch.Size([3, 480, 640])\n",
        "    # Match tensor type (`torch.FloatTensor` -> `torch.HalfTensor`) with model\n",
        "    image = image.half().to(device)\n",
        "    # Turn image into batch\n",
        "    image = image.unsqueeze(0) # torch.Size([1, 3, 480, 640])\n",
        "    output = model(image)\n",
        "    return output, image\n"
      ],
      "metadata": {
        "id": "p3Hot8H_u1Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(original_image, pred_img, pred_masks_np, nbboxes, pred_cls, pred_conf, plot_labels=True):\n",
        "  for one_mask, bbox, cls, conf in zip(pred_masks_np, nbboxes, pred_cls, pred_conf):\n",
        "    if conf < 0.25:\n",
        "        continue\n",
        "    color = [np.random.randint(255), np.random.randint(255), np.random.randint(255)]\n",
        "\n",
        "    pred_img = pred_img.copy()\n",
        "                             \n",
        "    # Apply mask over image in color\n",
        "    pred_img[one_mask] = pred_img[one_mask] * 0.5 + np.array(color, dtype=np.uint8) * 0.5\n",
        "    # Draw rectangles around all found objects\n",
        "    pred_img = cv2.rectangle(pred_img, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
        "\n",
        "    if plot_labels:\n",
        "      label = '%s %.3f' % (names[int(cls)], conf)\n",
        "      t_size = cv2.getTextSize(label, 0, fontScale=0.1, thickness=1)[0]\n",
        "      c2 = bbox[0] + t_size[0], bbox[1] - t_size[1] - 3\n",
        "      pred_img = cv2.rectangle(pred_img, (bbox[0], bbox[1]), c2, color, -1, cv2.LINE_AA)\n",
        "      pred_img = cv2.putText(pred_img, label, (bbox[0], bbox[1] - 2), 0, 0.5, [255, 255, 255], thickness=1, lineType=cv2.LINE_AA)  \n",
        "\n",
        "  fig, ax = plt.subplots(1, 2, figsize=(pred_img.shape[0]/10, pred_img.shape[1]/10), dpi=150)\n",
        "\n",
        "  original_image = np.moveaxis(image.cpu().numpy().squeeze(), 0, 2).astype('float32')\n",
        "  original_image = cv2.cvtColor(original_image, cv2.COLOR_RGB2BGR)\n",
        "  \n",
        "  ax[0].imshow(original_image)\n",
        "  ax[0].axis(\"off\")\n",
        "  ax[1].imshow(pred_img)\n",
        "  ax[1].axis(\"off\")"
      ],
      "metadata": {
        "id": "br6C4Ru9UHGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################################################################\n",
        "# Intialize a list containing the file names of the deepsense dataset images\n",
        "####################################################################################################################"
      ],
      "metadata": {
        "id": "GfdEfxyGJ5qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "directory = '/content/gdrive/MyDrive/Dataset/Scenario 5/camera_data'\n",
        "filenames = []\n",
        "for filename in os.listdir(directory):\n",
        "    if os.path.isfile(os.path.join(directory, filename)):\n",
        "        filenames.append(filename)\n",
        "\n",
        "print(filenames)"
      ],
      "metadata": {
        "id": "we9LrjLoUQJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################################################################################################\n",
        "# The cell below will obtain the masks of the cars and their bounding boxes and store it in in a pandas dataframe\n",
        "####################################################################################################################"
      ],
      "metadata": {
        "id": "IGweLNnMFkLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "p=0\n",
        "df = pd.DataFrame(columns=['Mask path', 'Bounding box coordinate 1', 'Bounding box coordinate 2', 'Bounding box coordinate 3', 'Bounding box coordinate 4', 'Number of cars'])\n",
        "for _,i in enumerate(filenames):\n",
        "  dummyfile_name = '/content/gdrive/MyDrive/Dataset/Scenario 5/camera_data/' + i\n",
        "  output, image = run_inference(dummyfile_name)\n",
        "  inf_out = output['test']\n",
        "  attn = output['attn']\n",
        "  bases = output['bases']\n",
        "  sem_output = output['sem']\n",
        "\n",
        "  bases = torch.cat([bases, sem_output], dim=1)\n",
        "  nb, _, height, width = image.shape\n",
        "  names = model.names\n",
        "  pooler_scale = model.pooler_scale\n",
        "\n",
        "  pooler = ROIPooler(output_size=hyp['mask_resolution'], \n",
        "                    scales=(pooler_scale,), \n",
        "                    sampling_ratio=1, \n",
        "                    pooler_type='ROIAlignV2', \n",
        "                    canonical_level=2)\n",
        "                    \n",
        "\n",
        "  output, output_mask, _, _, _ = non_max_suppression_mask_conf(inf_out, \n",
        "                                                              attn, \n",
        "                                                              bases, \n",
        "                                                              pooler, \n",
        "                                                              hyp, \n",
        "                                                              conf_thres=0.40, \n",
        "                                                              iou_thres=0.65, \n",
        "                                                              merge=False, \n",
        "                                                              mask_iou=None)  \n",
        "  \n",
        "\n",
        "  pred, pred_masks = output[0], output_mask[0]\n",
        "  base = bases[0]\n",
        "  bboxes = Boxes(pred[:, :4])\n",
        "\n",
        "  original_pred_masks = pred_masks.view(-1, \n",
        "                                        hyp['mask_resolution'], \n",
        "                                        hyp['mask_resolution'])\n",
        "\n",
        "  pred_masks = retry_if_cuda_oom(paste_masks_in_image)(original_pred_masks, \n",
        "                                                      bboxes, \n",
        "                                                      (height, width), \n",
        "                                                      threshold=0.5)\n",
        "                                                      \n",
        "  # Detach Tensors from the device, send to the CPU and turn into NumPy arrays\n",
        "  pred_masks_np = pred_masks.detach().cpu().numpy()\n",
        "  pred_cls = pred[:, 5].detach().cpu().numpy()\n",
        "  pred_conf = pred[:, 4].detach().cpu().numpy()\n",
        "  nimg = image[0].permute(1, 2, 0) * 255\n",
        "  nimg = nimg.cpu().numpy().astype(np.uint8)\n",
        "  nimg = cv2.cvtColor(nimg, cv2.COLOR_RGB2BGR)\n",
        "  nbboxes = bboxes.tensor.detach().cpu().numpy().astype(np.int)\n",
        "\n",
        "  num_cars = 0\n",
        "  o= 0\n",
        "  final_arr = np.zeros((540,960))\n",
        "  for one_mask, bbox, cls, conf in zip(pred_masks_np, nbboxes, pred_cls, pred_conf):\n",
        "    label = '%s %.3f' % (names[int(cls)], conf)\n",
        "    if \"car\" in label and conf>0.5:\n",
        "      final_arr = np.logical_or(final_arr, pred_masks_np[o][18:540+18,0:960])\n",
        "      o=o+1\n",
        "      num_cars =num_cars +1\n",
        "      if len(bbox.shape) == 1:\n",
        "        df = df.append({'Mask path': i, 'Bounding box coordinate 1':bbox[0] , 'Bounding box coordinate 2': bbox[1]+18, 'Bounding box coordinate 3':bbox[2]  , 'Bounding box coordinate 4': bbox[3]+18 , 'Number of cars': num_cars }, ignore_index=True)\n",
        "      else:\n",
        "        df = df.append({'Mask path': i, 'Bounding box coordinate 1':bbox[o][0] , 'Bounding box coordinate 2': bbox[o][1]+18, 'Bounding box coordinate 3':bbox[o][2]  , 'Bounding box coordinate 4': bbox[o][3]+18 , 'Number of cars': num_cars }, ignore_index=True)  \n",
        "\n",
        "  im = Image.fromarray(final_arr)\n",
        "\n",
        "  im.save('/content/gdrive/MyDrive/Dataset/Scenario 5/masks/' + i)    \n",
        "  p=p+1\n",
        "  if p%50 == 0:\n",
        "    print('50 done')\n",
        "\n"
      ],
      "metadata": {
        "id": "DjxKi-id8yxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "ASlQmmhW8JBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/gdrive/MyDrive/Dataset/Scenario 5/thecsvfile.csv')\n"
      ],
      "metadata": {
        "id": "rs4bEC24Yh1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}