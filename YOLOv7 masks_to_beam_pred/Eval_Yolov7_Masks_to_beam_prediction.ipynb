{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "###########################################################################################################################################################\n",
        "# Citations:\n",
        "# 1) Charan, G. (2020). Sensing-Aided-Drone-Beam-Prediction [Repository]. GitHub. https://github.com/gourangc/Sensing-Aided-Drone-Beam-Prediction\n",
        "# 2) Cheng, R. (2019). LeNet-5-Implementation-Using-Pytorch [Repository]. GitHub. https://github.com/lychengrex/LeNet-5-Implementation-Using-Pytorch\n",
        "###########################################################################################################################################################"
      ],
      "metadata": {
        "id": "W3N49nvM8LWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from natsort import natsorted\n",
        "import re\n",
        "import os\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "# from skimage import io\n",
        "import skimage\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import datetime\n",
        "import sys\n",
        "import torch as t\n",
        "import torch.cuda as cuda\n",
        "import torch.optim as optimizer\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, transform\n",
        "from scipy import io\n",
        "from torchsummary import summary\n",
        "import csv\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Set the scenario number\n",
        "scenario_numx = 7\n",
        "scenario_num = scenario_numx\n",
        "\n",
        "all_cars = True\n",
        "\n",
        "# Set the working directory appropriately in this variable\n",
        "directory = '/content/gdrive/MyDrive/Dataset/scenario' + str(scenario_numx)\n",
        "directory = directory + '/'\n",
        "\n",
        "# ! git clone https://github.com/gourangc/Vision-Position-Beam-Prediction.git"
      ],
      "metadata": {
        "id": "vskI7tECfyE2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1247b6a-165f-4ca9-8a92-c9f8d5d11175"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datafeed"
      ],
      "metadata": {
        "id": "uUvRdscQeuhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########################################################\n",
        "#  Generate the train, test and validation data first. \n",
        "########################################################"
      ],
      "metadata": {
        "id": "p6xQcik3ImM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MoUvXsZwbHYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Charan, G. (2020). Sensing-Aided-Drone-Beam-Prediction [Repository]. GitHub. https://github.com/gourangc/Sensing-Aided-Drone-Beam-Prediction\n",
        "\n",
        "'''\n",
        "A data feeding class. It generates a list of data samples, each of which is\n",
        "a tuple of a string (image path) and an integer (beam index), and it defines\n",
        "a data-fetching method.\n",
        "Author: Gouranga Charan\n",
        "Nov. 2020\n",
        "'''\n",
        "\n",
        "\n",
        "############### Create data sample list #################\n",
        "def create_samples(root, shuffle=False, nat_sort=False):\n",
        "    f = pd.read_csv(root)\n",
        "    data_samples = []\n",
        "    pred_val = []\n",
        "    for idx, row in f.iterrows():\n",
        "        img_paths = row.values\n",
        "        data_samples.append(img_paths)\n",
        "    \n",
        "    # print(data_samples)\n",
        "    return data_samples\n",
        "#############################################################\n",
        "\n",
        "class DataFeed(Dataset):\n",
        "    '''\n",
        "    A class retrieving a tuple of (image,label). It can handle the case\n",
        "    of empty classes (empty folders).\n",
        "    '''\n",
        "    def __init__(self,root_dir, nat_sort = False, transform=None, init_shuflle = True):\n",
        "        self.root = root_dir\n",
        "        self.samples = create_samples(self.root,shuffle=init_shuflle,nat_sort=nat_sort)\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len( self.samples )\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.samples[idx]\n",
        "        img = skimage.io.imread(directory +sample[5][2:])\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = sample[7]\n",
        "        return (img,label)"
      ],
      "metadata": {
        "id": "a5ekaAKDedUo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Buildnet"
      ],
      "metadata": {
        "id": "g3xR8-gbezrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cheng, R. (2019). LeNet-5-Implementation-Using-Pytorch [Repository]. GitHub. https://github.com/lychengrex/LeNet-5-Implementation-Using-Pytorch\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "\n",
        "    # network structure\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        return np.prod(size)     \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YPisi-Xx5hhD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main script"
      ],
      "metadata": {
        "id": "sqeb03Dve2T3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Charan, G. (2020). Sensing-Aided-Drone-Beam-Prediction [Repository]. GitHub. https://github.com/gourangc/Sensing-Aided-Drone-Beam-Prediction\n",
        "'''\n",
        "Main script\n",
        "Author: Gouranga Charan\n",
        "Nov. 2020\n",
        "'''\n",
        "\n",
        "isExists = os.path.exists(directory + 'checkpoint')\n",
        "if not isExists:\n",
        "    os.makedirs(directory + 'checkpoint') \n",
        "    \n",
        "isExists = os.path.exists(directory + 'saved_analysis_file')\n",
        "if not isExists:\n",
        "    os.makedirs(directory+'/saved_analysis_file')        \n",
        "\n",
        "# Hyper-parameters\n",
        "batch_size = 32\n",
        "val_batch_size = 1\n",
        "lr = 1e-2\n",
        "# decay = 1e-4\n",
        "image_grab = False\n",
        "num_epochs = 1\n",
        "train_size = [1]\n",
        "\n",
        "# Data pre-processing:\n",
        "img_resize = transf.Resize((28, 28))\n",
        "# img_norm = transf.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "proc_pipe = transf.Compose(\n",
        "    [transf.ToPILImage(),\n",
        "      img_resize,\n",
        "      transf.ToTensor()]\n",
        ")\n",
        "\n",
        "val_dir = '/content/scenario7_test.csv'\n",
        "\n",
        "# train_dir=val_dir\n",
        "\n",
        "\n",
        "val_loader = DataLoader(DataFeed(val_dir, transform=proc_pipe),\n",
        "                        batch_size=val_batch_size,\n",
        "                        shuffle=True)\n",
        "now = datetime.datetime.now()\n",
        "\n",
        "\n",
        "\n",
        "val_acc = []\n",
        "with cuda.device(0):\n",
        "    top_1 = np.zeros( (1,len(train_size)) )\n",
        "    top_2 = np.zeros( (1,len(train_size)) )\n",
        "    top_3 = np.zeros( (1,len(train_size)) )\n",
        "    acc_loss = 0\n",
        "    itr = []\n",
        "    for idx, n in enumerate(train_size):\n",
        "        print('```````````````````````````````````````````````````````')\n",
        "        print('Training size is {}'.format(n))\n",
        "        # Build the network:\n",
        "        net = LeNet()\n",
        "        net = net.cuda()\n",
        "        checkpoint_path = '/content/checkpoint_yolov7_scenario7'\n",
        "        net.load_state_dict(t.load(checkpoint_path))\n",
        "        net.eval()\n",
        "        layers = list(net.children())\n",
        "        summary(net.cuda(), (1, 28, 28))\n",
        "\n",
        "        #  Optimization parameters:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        # opt = optimizer.Adam(net.parameters(), lr=lr, weight_decay=decay)\n",
        "        opt = optimizer.Adam(net.parameters(), lr=lr)\n",
        "        # LR_sch = optimizer.lr_scheduler.MultiStepLR(opt, [4,8], gamma=0.1, last_epoch=-1)\n",
        "        LR_sch = optimizer.lr_scheduler.ReduceLROnPlateau(opt, 'min',patience=15, verbose=True, min_lr=1e-3)\n",
        "        count = 0\n",
        "        running_loss = []\n",
        "        running_top1_acc = []\n",
        "        running_top2_acc = []\n",
        "        running_top3_acc = []\n",
        "        \n",
        "        #allowed_batches = np.floor((n*3500)/batch_size)\n",
        "        for epoch in range(num_epochs):\n",
        "            # print('Training loss', + str(running_loss[-1]))\n",
        "            print('Start validation')\n",
        "            ave_top1_acc = 0\n",
        "            ave_top2_acc = 0\n",
        "            ave_top3_acc = 0\n",
        "            ind_ten = t.as_tensor([0, 1, 2], device='cuda:0')\n",
        "            top1_pred_out = []\n",
        "            top2_pred_out = []\n",
        "            top3_pred_out = []\n",
        "            total_count = 0\n",
        "            for val_count, (imgs, labels) in enumerate(val_loader):\n",
        "                net.eval()\n",
        "                imgs = torch.where(imgs<0.01, 0.0, 1.0)\n",
        "                x = imgs.cuda()\n",
        "                opt.zero_grad()\n",
        "                labels = labels.cuda()\n",
        "                total_count += labels.size(0)\n",
        "                out = net.forward(x)\n",
        "                sorted_out = t.argsort(out, dim=1, descending=True)\n",
        "\n",
        "                top_1_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:1])\n",
        "                top1_pred_out.append(top_1_pred.cpu().numpy())\n",
        "\n",
        "\n",
        "                top_2_pred = t.index_select(sorted_out, dim=1, index=ind_ten[0:2])\n",
        "                top2_pred_out.append(top_2_pred.cpu().numpy())\n",
        "\n",
        "\n",
        "                top_3_pred_0 = t.index_select(sorted_out, dim=1, index=ind_ten[0])\n",
        "                top_3_pred_1 = t.index_select(sorted_out, dim=1, index=ind_ten[1])\n",
        "                top_3_pred_2 = t.index_select(sorted_out, dim=1, index=ind_ten[2])\n",
        "                top_3_pred = t.index_select(sorted_out, dim=1, index=ind_ten)\n",
        "                tmp = [top_3_pred_0.item(), top_3_pred_1.item(), top_3_pred_2.item() ]\n",
        "                top3_pred_out.append(tmp) \n",
        "                reshaped_labels = labels.reshape((labels.shape[0], 1))\n",
        "                \n",
        "                tiled_2_labels = reshaped_labels.repeat(1, 2)\n",
        "                tiled_3_labels = reshaped_labels.repeat(1, 3)\n",
        "  \n",
        "                batch_top1_acc = t.sum(top_1_pred == labels, dtype=t.float32)\n",
        "                batch_top2_acc = t.sum(top_2_pred == tiled_2_labels, dtype=t.float32)\n",
        "                batch_top3_acc = t.sum(top_3_pred == tiled_3_labels, dtype=t.float32)\n",
        "                \n",
        "                ave_top1_acc += batch_top1_acc.item()\n",
        "                ave_top2_acc += batch_top2_acc.item()\n",
        "                ave_top3_acc += batch_top3_acc.item()\n",
        "            print(\"total test examples are\", total_count)\n",
        "            \n",
        "            running_top1_acc.append(ave_top1_acc / total_count)\n",
        "            running_top2_acc.append(ave_top2_acc / total_count)\n",
        "            running_top3_acc.append(ave_top3_acc / total_count)  # (batch_size * (count_2 + 1)))\n",
        "\n",
        "            print('Average Top-1 accuracy {}'.format( running_top1_acc[-1]))\n",
        "            print('Average Top-2 accuracy {}'.format( running_top2_acc[-1]))\n",
        "            print('Average Top-3 accuracy {}'.format( running_top3_acc[-1]))\n",
        "            print(\"Saving the predicted value in a csv file\")\n",
        "            tmp = [running_top2_acc[-1],running_top3_acc[-1]]\n",
        "            val_acc.append(tmp)\n",
        "            \n",
        "\n",
        "            with open(directory +\"/saved_analysis_file/top1_pred_beam_val_after_%sth_epoch.csv\"%(epoch+1), \"w\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerows(zip(top1_pred_out))\n",
        "\n",
        "\n",
        "            with open(directory + \"/saved_analysis_file/top2_pred_beam_val_after_%sth_epoch.csv\"%(epoch+1), \"w\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerows(zip(top2_pred_out))  \n",
        "\n",
        "            with open(directory + \"saved_analysis_file/top3_pred_beam_val_after_%sth_epoch.csv\"%(epoch+1), \"w\", newline=\"\") as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerows(zip(top3_pred_out))    \n",
        "\n",
        "            net_name = 'modelafter' +str(epoch) + 'epoch'\n",
        "            t.save(net.state_dict(), net_name)               \n",
        "\n",
        "            # LR_sch.step(L)\n",
        "        top_1[0,idx] = running_top1_acc[-1]\n",
        "        top_2[0,idx] = running_top2_acc[-1]\n",
        "        top_3[0,idx] = running_top3_acc[-1]\n",
        "with open(directory + \"val_acc_32_beams.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerows(val_acc)      \n",
        "net_name = directory +'checkpoint/img_beam_pred_ckpt'\n",
        "t.save(net.state_dict(), net_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "SNfL62RpZtap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b710a62c-776e-4b16-986d-4e8c69bf4ebb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```````````````````````````````````````````````````````\n",
            "Training size is 1\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 6, 28, 28]             156\n",
            "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
            "            Linear-3                  [-1, 120]          48,120\n",
            "            Linear-4                   [-1, 84]          10,164\n",
            "            Linear-5                   [-1, 64]           5,440\n",
            "================================================================\n",
            "Total params: 66,296\n",
            "Trainable params: 66,296\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.25\n",
            "Estimated Total Size (MB): 0.31\n",
            "----------------------------------------------------------------\n",
            "Start validation\n",
            "total test examples are 86\n",
            "Average Top-1 accuracy 0.38372093023255816\n",
            "Average Top-2 accuracy 0.7325581395348837\n",
            "Average Top-3 accuracy 0.872093023255814\n",
            "Saving the predicted value in a csv file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cr-wdAD_Ztlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6P_PExbbZuZm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
